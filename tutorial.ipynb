{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the [Data-driven Methods for Network-level Coordination of Autonomous Mobility-on-Demand Systems Across Scales](https://rl4amod-itsc24.github.io/) coding tutorial, presented at 27th IEEE ITSC 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/gnn-for-amod.png\" width=\"700\"/></td> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join us in moving the first steps toward the creation of publicly available benchmarks, datasets, and simulators for network-level coordination of MoD systems.\n",
    "\n",
    "This notebook offers an interactive, hands-on session for benchmarking AMoD controllers across \n",
    "- openly accessible simulation platforms across different fidelity levels \n",
    "- calibareted scenarios calibrat \n",
    "- Implementation of fleet coordination algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hydra-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PuLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install traci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/StanfordASL/RL4AMOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd RL4AMOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The macro environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The macro envorinment is based on taxi record data colleted in various city, e.g. New York City, San Francisco, Washignton DC, Shenzhen. In each scenarion, the road network is segmented into stations by clustering junctions such that the travel time within each station is upper-bounded by a given error tolerance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are looking at the nyc brooklyn scenario. It exists of 14 clustered regions with the following demand distribution: \n",
    "\n",
    "<img src=\"figures/demand_profit.png\" alt=\"drawing\" style=\"background-color: white; border: 1px solid black;\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository provides a set of baseline policies, that aim to outperform the no-control policy, which serves as the lower bound. \n",
    "The simplest of these is the random rebalancing policy. We evaluate its performance against the no-control policy by assessing total profit, calculated as the profit from passengers served minus the cost of rebalancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'testing' from '/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/testing.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"macro\",\n",
    "    \"model.name\": \"random\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "}\n",
    "!pwd\n",
    "testing.test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s no surprise that the random rebalancing policy fails to outperform the no-control policy. As shown in the figure on the right, it tends to relocate many vehicles to low-demand regions, resulting in inefficient rebalancing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement your own controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random rebalancing policy is not able to outperform the no control baseline, so let's implement a policy that does. We can develop a control policy that aims to achieve an equal distribution of vehicles across the network while minimizing rebalancing costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.misc.utils import dictsum\n",
    "from src.algos.reb_flow_solver import solveRebFlow\n",
    "from src.algos.base import BaseAlgorithm\n",
    "\n",
    "\n",
    "class EqualDistribution(BaseAlgorithm):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        :param cplexpath: Path to the CPLEX solver.\n",
    "        \"\"\"\n",
    "        self.cplexpath = kwargs.get('cplexpath') #None, for no CPLEX\n",
    "\n",
    "    def select_action(self, env):\n",
    "        \"\"\"\n",
    "        Implements the Equal Distribution (ED) baseline for rebalancing.\n",
    "        :param env: The current state of the environment\n",
    "        :return: The rebalancing action to be taken\n",
    "        \"\"\"\n",
    "        # number of regions in this scenario\n",
    "        nregions = env.nregion\n",
    "        \n",
    "        #determines the desired vehicle distirbutions\n",
    "        action = [1 / nregions for _ in range(nregions)]\n",
    "        \n",
    "        #calculates the desired number of vehicles in each region\n",
    "        desired_acc = {\n",
    "            env.region[i]: int(action[i] * dictsum(env.acc, env.time +1))\n",
    "            for i in range(len(env.region))\n",
    "        }\n",
    "        \n",
    "        #calculated the min-cost rebalancing flow to reach desried distirbution\n",
    "        reb_action = solveRebFlow(env, desired_acc, self.cplexpath) \n",
    "        \n",
    "        return reb_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test this new policy and compare it to the no control baseline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"simulator.name\": \"macro\",\n",
    "    \"model.name\": \"equal_distribution\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "}\n",
    "testing.test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the equal distribution policy significantly boosts profit compared to the no-control baseline, the rebalancing flows still don't align entirely with the demand distribution. (e.g. region 10 and 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RL-based policies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the equal distribution policy already significantly outperforms the no-control baseline, it remains a reactive approach. Instead of relying on a policy that enforces an equal distribution of idle vehicles, we can implement a reinforcement learning (RL) policy that proactively adjusts the distribution based on the current state. \n",
    "\n",
    "In this repository, we already provide a pre-trained agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from testing import test\n",
    "config = {\n",
    "    \"simulator.name\": \"macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_nyc_brooklyn\"\n",
    "}\n",
    "testing.test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Saving sampled demand to saved_files/sample_demand_20250826-141941_supply_factor_4_firm_count_4_dm_portion.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ckpt/SAC_nyc_4_firms_flow_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      8\u001b[39m importlib.reload(testing)\n\u001b[32m      9\u001b[39m config = {\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msimulator.name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmulti_macro\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel.name\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33msac\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mequal_distribution\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msimulator.constant_vehicle_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     20\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mtesting\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/testing.py:158\u001b[39m, in \u001b[36mmulti_test\u001b[39m\u001b[34m(input_config)\u001b[39m\n\u001b[32m    155\u001b[39m     use_cuda = \u001b[38;5;129;01mnot\u001b[39;00m cfg.model.no_cuda \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available()\n\u001b[32m    156\u001b[39m     device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     profit, inflows = \u001b[43mtest_approach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     data[\u001b[32m0\u001b[39m][config[\u001b[33m\"\u001b[39m\u001b[33mmodel.name\u001b[39m\u001b[33m\"\u001b[39m]], data[\u001b[32m1\u001b[39m][config[\u001b[33m'\u001b[39m\u001b[33mmodel.name\u001b[39m\u001b[33m'\u001b[39m]] = profit, inflows\n\u001b[32m    161\u001b[39m control_data = get_no_control_performance(cfg, env, parser, device, use_saved_data=cfg.simulator.reuse_no_control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/testing.py:198\u001b[39m, in \u001b[36mtest_approach\u001b[39m\u001b[34m(cfg, env, parser, device)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mtest_approach\u001b[39m(cfg, env, parser, device):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     model = \u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTesting model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.model.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.simulator.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m environment\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    202\u001b[39m     episode_reward, episode_served_demand, episode_rebalancing_cost, inflows = model.test(cfg.model.test_episodes, env)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/testing.py:101\u001b[39m, in \u001b[36msetup_model\u001b[39m\u001b[34m(cfg, env, parser, device)\u001b[39m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgos\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msac\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SAC\n\u001b[32m    100\u001b[39m     model= SAC(env=env, input_size=cfg.model.input_size, cfg=cfg.model, parser=parser, device=device).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mckpt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_best.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_name == \u001b[33m\"\u001b[39m\u001b[33ma2c\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/src/algos/sac.py:662\u001b[39m, in \u001b[36mSAC.load_checkpoint\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mload_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, path=\u001b[33m\"\u001b[39m\u001b[33mckpt.pth\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    664\u001b[39m         \u001b[38;5;66;03m# Attempt to load the model state dict as is\u001b[39;00m\n\u001b[32m    665\u001b[39m         \u001b[38;5;28mself\u001b[39m.load_state_dict(checkpoint[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/serialization.py:998\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m    995\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m    996\u001b[39m     pickle_load_args[\u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m    999\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1000\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1001\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1002\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1003\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/serialization.py:445\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    447\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/serialization.py:426\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'ckpt/SAC_nyc_4_firms_flow_best.pth'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"older/SAC_nyc_4_firms_flow\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 4,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True\n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With not changing x\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"equal_distribution\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "}\n",
    "testing.test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"random\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "}\n",
    "testing.test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/comparison_final.png\" alt=\"drawing\" style=\"background-color: white; border: 1px solid black;\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement an RL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally policy takes the current state as input and outputs the next action $\\pi(a_t | s_t)$:\n",
    "\n",
    "<img src=\"figures/NN_Actor.png\" alt=\"drawing\" style=\"background-color: white; border: 1px solid black;\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Dirichlet\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor \\pi(a_t | s_t) parametrizing the concentration parameters of a Dirichlet Policy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, act_dim, hidden_size=32):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        in_channels: state dimension\n",
    "        act_dim: action dimension\n",
    "        \"\"\"\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(hidden_size, act_dim)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.lin1(state))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.softplus(self.lin3(x))\n",
    "    \n",
    "        concentration = x.squeeze(-1)\n",
    "        m = Dirichlet(concentration + 1e-20)\n",
    "        action = m.sample()\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "The state consits of 14 regions/nodes with 13 node features each\n",
    "'''\n",
    "state = torch.ones(14, 13) \n",
    "\n",
    "state = state.flatten() #MLP expects a vector input\n",
    "\n",
    "actor = Actor(in_channels=14*13, act_dim=14)\n",
    "\n",
    "action = actor(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(14), action.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Dirichlet\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GNNActor(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor \\pi(a_t | s_t) parametrizing the concentration parameters of a Dirichlet Policy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_size=32, act_dim=6):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.act_dim = act_dim\n",
    "        self.conv1 = GCNConv(in_channels, in_channels)\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, state, edge_index):\n",
    "        out = F.relu(self.conv1(state, edge_index))\n",
    "        x = out + state\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.softplus(self.lin3(x))\n",
    "        \n",
    "        concentration = x.squeeze(-1)\n",
    "        m = Dirichlet(concentration + 1e-20)\n",
    "        action = m.sample()\n",
    "           \n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.ones(14, 13) \n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13],\n",
    "                           [1, 0, 2, 1, 3, 2, 4, 3, 5, 4, 6, 5, 7, 6, 8, 7, 9, 8, 10, 9, 11, 10, 12, 11, 13, 12]])\n",
    "\n",
    "actor = GNNActor(in_channels=13)\n",
    "\n",
    "action = actor(state, edge_index)\n",
    "\n",
    "plt.bar(range(14), action.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an RL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portion based / Constant Vehicle Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/_C.cpython-312-darwin.so, 0x0002): Library not loaded: @loader_path/libtorch_cpu.dylib\n  Referenced from: <BF62FCCB-56C3-3F10-8807-63842A41DC44> /Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_python.dylib\n  Reason: tried: '/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_cpu.dylib' (no such file), '/usr/local/lib/libtorch_cpu.dylib' (no such file), '/usr/lib/libtorch_cpu.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtesting\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      4\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/testing.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mhydra\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictConfig\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mjson\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/__init__.py:237\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    236\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[31mImportError\u001b[39m: dlopen(/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/_C.cpython-312-darwin.so, 0x0002): Library not loaded: @loader_path/libtorch_cpu.dylib\n  Referenced from: <BF62FCCB-56C3-3F10-8807-63842A41DC44> /Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_python.dylib\n  Reason: tried: '/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_cpu.dylib' (no such file), '/usr/local/lib/libtorch_cpu.dylib' (no such file), '/usr/lib/libtorch_cpu.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_portion_2\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_portion_2_test_train\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/_C.cpython-312-darwin.so, 0x0002): Library not loaded: @loader_path/libtorch_cpu.dylib\n  Referenced from: <BF62FCCB-56C3-3F10-8807-63842A41DC44> /Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_python.dylib\n  Reason: tried: '/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_cpu.dylib' (no such file), '/usr/local/lib/libtorch_cpu.dylib' (no such file), '/usr/lib/libtorch_cpu.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtesting\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys.modules:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m sys.modules[\u001b[33m'\u001b[39m\u001b[33mtesting\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtesting\u001b[39;00m\n\u001b[32m      8\u001b[39m importlib.reload(testing)\n\u001b[32m      9\u001b[39m config = {\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msimulator.name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmulti_macro\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel.name\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33msac\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mequal_distribution\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msimulator.demand_filter_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mportion\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m     21\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/testing.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mhydra\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictConfig\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mjson\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/__init__.py:237\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    236\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[31mImportError\u001b[39m: dlopen(/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/_C.cpython-312-darwin.so, 0x0002): Library not loaded: @loader_path/libtorch_cpu.dylib\n  Referenced from: <BF62FCCB-56C3-3F10-8807-63842A41DC44> /Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_python.dylib\n  Reason: tried: '/Users/victoria_tuck/Documents/Doctorate/Research_Projects/Strategic_Dynamic_Routing/RL4AMOD/venv/lib/python3.12/site-packages/torch/lib/libtorch_cpu.dylib' (no such file), '/usr/local/lib/libtorch_cpu.dylib' (no such file), '/usr/lib/libtorch_cpu.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 2,\n",
    "    \"model.checkpoint_path\": \"SAC_portion_2\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 2,\n",
    "    \"model.checkpoint_path\": \"SAC_portion_2_test_train\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_portion_3\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 3,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_portion_3\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 3,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_portion_4\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 4,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_portion_4\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 4,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow based / Constant Vehicle Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_flow_2\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\"  # or portion\n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_flow_2\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_flow_3\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 3,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\" \n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_flow_3\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 3,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": \"sac\",\n",
    "    \"simulator.city\": \"nyc_brooklyn\",\n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.checkpoint_path\": \"SAC_flow_4\",\n",
    "    \"model.max_episodes\": 50,\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 4,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\" \n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_flow_4\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 4,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portion based / Testing Random initial distribution - No retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    # \"model.name\": [\"sac\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 1,\n",
    "    \"model.checkpoint_path\": \"SAC_portion_2\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"portion\" ,\n",
    "    # \"simulator.initial_vehicle_distribution\": \"random\", # or None\n",
    "    \"simulator.pricing_model\": \"cournot\"\n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an initial plot of the scenario demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the code below all you have to do is specify the vehicle distribution file after running testing and the demand file, usually have the same timestamp. Make sure you use the scenario you ran the testing on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "# historical\n",
    "current_folder = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "with open(f\"{current_folder}/src/envs/data/multi_macro/scenario_nyc_brooklyn.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "all_nodes = sorted(set(edge[\"i\"] for edge in data[\"topology_graph\"]) | set(edge[\"j\"] for edge in data[\"topology_graph\"]))\n",
    "all_edges = [(edge[\"i\"], edge[\"j\"]) for edge in data[\"topology_graph\"]]\n",
    "print(\"Total number of nodes:\", len(all_nodes), \"Total number of edges:\", len(all_edges))\n",
    "# nlat = data[\"nlat\"]\n",
    "# nlon = data[\"nlon\"]\n",
    "nlat = 4\n",
    "nlon = 4\n",
    "pos = {i: (i % nlon, nlat - i // nlon) for i in all_nodes}\n",
    "\n",
    "df = pd.DataFrame(data[\"demand\"])\n",
    "min_time = df[\"time_stamp\"].min()\n",
    "max_time = df[\"time_stamp\"].max()\n",
    "n_timesteps = df[\"time_stamp\"].nunique()\n",
    "\n",
    "print(\"Number of timesteps:\", n_timesteps)\n",
    "print(\"First timestep:\", min_time)\n",
    "print(\"Last timestep:\", max_time)\n",
    "\n",
    "\n",
    "timestep = min_time  \n",
    "df_t = df[df[\"time_stamp\"] == timestep].copy()\n",
    "\n",
    "# print(f\"\\nDemand data at timestep {timestep}:\")\n",
    "# print(df_t[[\"origin\", \"destination\", \"demand\", \"price\", \"travel_time\"]])\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(all_nodes)\n",
    "\n",
    "# Filter timestep\n",
    "df_t = df[df[\"time_stamp\"] == timestep]\n",
    "active_edges = df_t[[\"origin\", \"destination\"]].values.tolist()\n",
    "G.add_edges_from(active_edges)\n",
    "print(f\"Number of active edges at timestep {timestep}: {len(active_edges)}\")\n",
    "\n",
    "edge_demand = {(row[\"origin\"], row[\"destination\"]): row[\"demand\"] for _, row in df_t.iterrows()}\n",
    "edges = list(edge_demand.keys())\n",
    "demands = list(edge_demand.values())\n",
    "norm = mcolors.Normalize(vmin=min(demands), vmax=max(demands))\n",
    "cmap = cm.tab20b # viridis, plasma, inferno, etc.\n",
    "edge_colors = [cmap(norm(d)) for d in demands]\n",
    "\n",
    "\n",
    "# ---- getting the sampled demadn\n",
    "json_hr = 19  \n",
    "json_tstep = 4  \n",
    "\n",
    "json_start = json_hr * 60  # base time in minutes\n",
    "print(f\"json_start: {json_start}, json_tstep: {json_tstep}\")\n",
    "\n",
    "with open(f\"{current_folder}/saved_files/sample_demand_20250805-132751_supply_factor_2_firm_count_2_dm_portion.json\", \"r\") as f:\n",
    "    sampled_data = json.load(f)\n",
    "df_sampled = pd.DataFrame(sampled_data, columns=[\"origin\", \"destination\", \"time_stamp\", \"sampled_demand\", \"sampled_price\"])\n",
    "\n",
    "df_sampled[\"time_stamp\"] = df_sampled[\"time_stamp\"] * json_tstep + json_start\n",
    "df_sampled[\"time_stamp\"] = df_sampled[\"time_stamp\"].astype(int)\n",
    "df_sampled = df_sampled[df_sampled[\"sampled_demand\"] != 0]\n",
    "df_t_sampled = df_sampled[df_sampled[\"time_stamp\"] == timestep]\n",
    "# print(df_sampled)\n",
    "current_demand_edges = df_t_sampled[[\"origin\", \"destination\"]].values.tolist()\n",
    "\n",
    "G_sampled = nx.DiGraph()\n",
    "G_sampled.add_nodes_from(all_nodes)\n",
    "G_sampled.add_edges_from(current_demand_edges)\n",
    "\n",
    "print(f\"Number of active sampled edges at timestep {timestep}: {len(current_demand_edges)}\")\n",
    "\n",
    "edge_demand_sampled = {(row[\"origin\"], row[\"destination\"]): row[\"sampled_demand\"] for _, row in df_t_sampled.iterrows()}\n",
    "edges_sampled = list(edge_demand_sampled.keys())\n",
    "demands_sampled = list(edge_demand_sampled.values())\n",
    "norm_sampled = mcolors.Normalize(vmin=min(demands_sampled ), vmax=max(demands_sampled ))\n",
    "cmap = cm.tab20b \n",
    "edge_colors_sampled = [cmap(norm_sampled(d)) for d in demands_sampled]\n",
    "\n",
    "\n",
    "# --- getting the vehicle distribution\n",
    "with open(f\"{current_folder}/saved_files/vehicle_distribution_20250811-133506_sac_supply_factor_2_firm_count_2_dm_portion.json\", \"r\") as f:\n",
    "    vehicle_distribution= json.load(f)\n",
    "vehicle_distribution = {int(t): {int(k): v for k, v in v.items()} for t, v in vehicle_distribution.items()}\n",
    "\n",
    "# Function to find the corresponding vehicle snapshot timestep\n",
    "def get_vehicle_timestep(minute, json_start, json_tstep):\n",
    "    return (minute - json_start) // json_tstep\n",
    "\n",
    "vehicle_time_idx = get_vehicle_timestep(timestep, json_start=json_start, json_tstep=json_tstep)\n",
    "vehicle_counts = vehicle_distribution.get(vehicle_time_idx, {})\n",
    "\n",
    "\n",
    "\n",
    "# ----- plotting both\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), facecolor=\"white\")\n",
    "nx.draw_networkx_nodes(G, pos, node_size=400, node_color=\"lightblue\", ax=axs[0])\n",
    "nx.draw_networkx_labels(G, pos, ax=axs[0])\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edge_demand.keys(), edge_color=edge_colors, width=2, arrows=True, ax=axs[0])\n",
    "sm_hist = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm_hist.set_array([])\n",
    "cbar = plt.colorbar(sm_hist, ax=axs[0], shrink=0.8)\n",
    "cbar.set_label(\"Demand\")\n",
    "axs[0].set_title(f\"Historical Demand - Timestep {timestep}\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "# plt.figure(figsize=(14,10), facecolor=\"white\") \n",
    "# ax = plt.gca()\n",
    "\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=400, node_color=\"lightblue\")\n",
    "# nx.draw_networkx_labels(G, pos)\n",
    "# nx.draw_networkx_edges(G, pos, width=2, arrowsize=14,\n",
    "#                        edgelist=edges, edge_color=edge_colors, arrows=True, ax=ax)\n",
    "\n",
    "# sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "# sm.set_array([])\n",
    "# cbar = plt.colorbar(sm, ax= ax, shrink=0.8)\n",
    "# cbar.set_label('Demand')\n",
    "# plt.title(f\"Historical - Demand Edges at Timestep {timestep}\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "nx.draw_networkx_nodes(G_sampled, pos, node_size=400, node_color=\"lightblue\", ax=axs[1])\n",
    "nx.draw_networkx_labels(G_sampled, pos, ax=axs[1])\n",
    "nx.draw_networkx_edges(G_sampled, pos, edgelist=edges_sampled, edge_color=edge_colors_sampled, width=2, arrows=True, ax=axs[1])\n",
    "sm_sampled = plt.cm.ScalarMappable(cmap=cmap, norm=norm_sampled)\n",
    "sm_sampled.set_array([])\n",
    "cbar = plt.colorbar(sm_sampled, ax=axs[1], shrink=0.8)\n",
    "cbar.set_label(\"Demand\")\n",
    "axs[1].set_title(f\"Sampled Demand - Timestep {timestep}\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "\n",
    "for node, count in vehicle_counts.items():\n",
    "    if count > 0:\n",
    "        axs[1].text(\n",
    "            pos[node][0] + 0.15,  # x-offset from node\n",
    "            pos[node][1] + 0.15,  # y-offset from node\n",
    "            f\"{int(count)}\",      # label text\n",
    "            fontsize=12,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"yellow\", alpha=0.6),\n",
    "            ha='center'\n",
    "        )\n",
    "\n",
    "vehicle_patch = mpatches.Patch(\n",
    "    facecolor='yellow',\n",
    "    edgecolor='black',\n",
    "    alpha=0.6,\n",
    "    label='Vehicle Count'\n",
    ")\n",
    "\n",
    "axs[1].legend(handles=[vehicle_patch], loc='lower right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(14, 10), facecolor=\"white\") \n",
    "# ax = plt.gca()\n",
    "\n",
    "# nx.draw_networkx_nodes(G_sampled, pos, node_size=400, node_color=\"lightblue\")\n",
    "# nx.draw_networkx_labels(G_sampled, pos)\n",
    "# nx.draw_networkx_edges(G_sampled, pos, width=2, arrowsize=14,\n",
    "#                        edgelist=edges_sampled, edge_color=edge_colors_sampled, arrows=True, ax=ax)\n",
    "\n",
    "# sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "# sm.set_array([])\n",
    "# cbar = plt.colorbar(sm, ax=ax, shrink=0.8)\n",
    "# cbar.set_label('Demand')\n",
    "# plt.title(f\"Sampled Demand Edges at Timestep {timestep}\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.merge(\n",
    "    df_t[[\"origin\", \"destination\", \"demand\", \"price\"]],\n",
    "    df_t_sampled[[\"origin\", \"destination\", \"sampled_demand\", \"sampled_price\"]],\n",
    "    how=\"outer\", on=[\"origin\", \"destination\"]\n",
    ").fillna(0)\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "df_summary_total = pd.merge(\n",
    "    df[[\"time_stamp\", \"origin\", \"destination\", \"demand\", \"price\", \"travel_time\"]],\n",
    "    df_sampled[[\"time_stamp\",\"origin\", \"destination\", \"sampled_demand\", \"sampled_price\"]],\n",
    "    how=\"outer\", on=[\"time_stamp\",\"origin\", \"destination\"]\n",
    ").fillna(0)\n",
    "display(HTML('<div style=\"height:400px; overflow:auto;\">' + df_summary_total.to_html() + '</div>'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(vehicle_distribution)): \n",
    "    start_minute = json_start + t * json_tstep\n",
    "    end_minute = start_minute + json_tstep\n",
    "\n",
    "    # Filter and aggregate demand between [start_minute, end_minute)\n",
    "    df_t = df[(df[\"time_stamp\"] >= start_minute) & (df[\"time_stamp\"] < end_minute)].copy()\n",
    "    edge_demand = df_t.groupby([\"origin\", \"destination\"])[\"demand\"].sum().to_dict()\n",
    "    edges = list(edge_demand.keys())\n",
    "    demands = list(edge_demand.values())\n",
    "    \n",
    "\n",
    "    norm = mcolors.Normalize(vmin=min(demands), vmax=max(demands)) if demands else mcolors.Normalize(vmin=0, vmax=1)\n",
    "    edge_colors = [cmap(norm(d)) for d in demands] if demands else []\n",
    "\n",
    "    # Sampled demand (already in the same timestep format)\n",
    "    df_t_sampled = df_sampled[df_sampled[\"time_stamp\"] == start_minute]\n",
    "    edge_demand_sampled = {(row[\"origin\"], row[\"destination\"]): row[\"sampled_demand\"] for _, row in df_t_sampled.iterrows()}\n",
    "    edges_sampled = list(edge_demand_sampled.keys())\n",
    "    demands_sampled = list(edge_demand_sampled.values())\n",
    "    \n",
    "\n",
    "    norm_sampled = mcolors.Normalize(vmin=min(demands_sampled), vmax=max(demands_sampled)) if demands_sampled else mcolors.Normalize(vmin=0, vmax=1)\n",
    "    edge_colors_sampled = [cmap(norm_sampled(d)) for d in demands_sampled] if demands_sampled else []\n",
    "\n",
    "    vehicle_counts = vehicle_distribution.get(t, {})\n",
    "    \n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 6), facecolor=\"white\")\n",
    "\n",
    "    # Historical demand (aggregated over the timestep)\n",
    "    G.clear()\n",
    "    G.add_nodes_from(all_nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=400, node_color=\"lightblue\", ax=axs[0])\n",
    "    nx.draw_networkx_labels(G, pos, ax=axs[0])\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=edge_colors, width=2, arrows=True, ax=axs[0])\n",
    "    sm_hist = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm_hist.set_array([])\n",
    "    plt.colorbar(sm_hist, ax=axs[0], shrink=0.8).set_label(\"Demand\")\n",
    "    axs[0].set_title(f\"Historical Demand - Timestep {t} ({start_minute}â€“{end_minute})\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    # Sampled demand\n",
    "    G_sampled.clear()\n",
    "    G_sampled.add_nodes_from(all_nodes)\n",
    "    G_sampled.add_edges_from(edges_sampled)\n",
    "    nx.draw_networkx_nodes(G_sampled, pos, node_size=400, node_color=\"lightblue\", ax=axs[1])\n",
    "    nx.draw_networkx_labels(G_sampled, pos, ax=axs[1])\n",
    "    nx.draw_networkx_edges(G_sampled, pos, edgelist=edges_sampled, edge_color=edge_colors_sampled, width=2, arrows=True, ax=axs[1])\n",
    "    sm_sampled = plt.cm.ScalarMappable(cmap=cmap, norm=norm_sampled)\n",
    "    sm_sampled.set_array([])\n",
    "    plt.colorbar(sm_sampled, ax=axs[1], shrink=0.8).set_label(\"Demand\")\n",
    "    axs[1].set_title(f\"Sampled Demand - Timestep {t} (minute {start_minute})\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    for node, count in vehicle_counts.items():\n",
    "        if count > 0:\n",
    "            axs[1].text(\n",
    "                pos[node][0] + 0.15,\n",
    "                pos[node][1] + 0.15,\n",
    "                f\"{int(count)}\",\n",
    "                fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"yellow\", alpha=0.6),\n",
    "                ha='center'\n",
    "            )\n",
    "\n",
    "    vehicle_patch = mpatches.Patch(facecolor='yellow', edgecolor='black', alpha=0.6, label='Vehicle Count')\n",
    "    axs[1].legend(handles=[vehicle_patch], loc='lower right', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if 'testing' in sys.modules:\n",
    "    del sys.modules['testing']\n",
    "\n",
    "import testing\n",
    "importlib.reload(testing)\n",
    "config = {\n",
    "    \"simulator.name\": \"multi_macro\",\n",
    "    \"model.name\": [\"sac\", \"equal_distribution\", \"random\"],\n",
    "    \"simulator.city\": \"nyc_brooklyn\", \n",
    "    \"model.cplexpath\": None, \n",
    "    \"model.test_episodes\": 10,\n",
    "    \"model.checkpoint_path\": \"SAC_flow_2\",\n",
    "    \"simulator.reuse_no_control\": False,\n",
    "    \"simulator.firm_count\": 2,\n",
    "    \"simulator.agents_know_partial_demand\": True,\n",
    "    \"simulator.constant_vehicle_count\": True,\n",
    "    \"simulator.demand_filter_type\": \"flow\" \n",
    "}\n",
    "testing.multi_test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional: SUMO Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SUMO environment is built around a mesoscopic traffic simulator using the Simulation of Urban MObility (SUMO) framework. The available scenario is based on the city of Luxembourg, utilizing the LuST Scenario (https://github.com/lcodeca/lux), where the traffic demand has been derived from a calibrated trips file. To create a more simplified and abstract representation of the city, the road network has been spatially aggregated into 10 regions, resulting in a coarser graph of the urban landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/lux_net.png\" alt=\"drawing\" width=\"500\"/>    <img src=\"figures/lux_net_aggregated.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\"simulator.name\": \"sumo\",\n",
    "\"model.name\": \"mpc\",\n",
    "\"simulator.city\": \"lux\",\n",
    "\"model.cplexpath\": None, \n",
    "\"model.test_episodes\": 1,\n",
    "}\n",
    "test(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
